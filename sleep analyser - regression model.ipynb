{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2466df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jazil\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d95f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_excel(r\"C:\\Users\\jazil\\OneDrive\\pep-ds\\sleep-proj\\Balanced_Sleep_Quality_Data.xlsx\")\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.drop(columns=['Person ID', 'Quality of Sleep'])\n",
    "y = df['Quality of Sleep']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocess data upfront: encode categorical and scale numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "        ('num', StandardScaler(), numerical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23aa11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the entire dataset once\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the Optuna objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters for Random Forest\n",
    "    rf_n_estimators = trial.suggest_int('rf_n_estimators', 100, 300)\n",
    "    rf_max_depth = trial.suggest_int('rf_max_depth', 5, 15)\n",
    "\n",
    "    # Suggest hyperparameters for Neural Network\n",
    "    nn_units1 = trial.suggest_int('nn_units1', 50, 200)\n",
    "    nn_units2 = trial.suggest_int('nn_units2', 25, 100)\n",
    "    nn_alpha = trial.suggest_float('nn_alpha', 1e-5, 1e-3, log=True)\n",
    "\n",
    "    # Define base learners\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=rf_n_estimators,\n",
    "        max_depth=rf_max_depth,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    nn_model = MLPRegressor(\n",
    "        hidden_layer_sizes=(nn_units1, nn_units2),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        random_state=42,\n",
    "        max_iter=500,\n",
    "        alpha=nn_alpha,\n",
    "        early_stopping=True\n",
    "    )\n",
    "     # Define meta-learner\n",
    "    meta_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "    stacking_regressor = StackingRegressor(\n",
    "        estimators=[\n",
    "            ('rf', rf_model),\n",
    "            ('nn', nn_model),\n",
    "        ],\n",
    "        final_estimator=meta_model,\n",
    "        cv=5,\n",
    "        passthrough=False\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = stacking_regressor.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bdc9ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 15:04:01,614] A new study created in memory with name: no-name-df4c92cc-fabb-4bd1-a55d-18133ece03db\n",
      "[I 2025-06-09 15:04:11,726] Trial 0 finished with value: 0.8288140343239875 and parameters: {'rf_n_estimators': 175, 'rf_max_depth': 15, 'nn_units1': 160, 'nn_units2': 70, 'nn_alpha': 2.0513382630874486e-05}. Best is trial 0 with value: 0.8288140343239875.\n",
      "[I 2025-06-09 15:04:20,477] Trial 1 finished with value: 0.8704909379546529 and parameters: {'rf_n_estimators': 131, 'rf_max_depth': 5, 'nn_units1': 180, 'nn_units2': 70, 'nn_alpha': 0.0002607024758370766}. Best is trial 1 with value: 0.8704909379546529.\n",
      "[I 2025-06-09 15:04:28,948] Trial 2 finished with value: 0.8759915953609922 and parameters: {'rf_n_estimators': 104, 'rf_max_depth': 15, 'nn_units1': 175, 'nn_units2': 41, 'nn_alpha': 2.3102018878452926e-05}. Best is trial 2 with value: 0.8759915953609922.\n",
      "[I 2025-06-09 15:04:35,487] Trial 3 finished with value: 0.8815891880052097 and parameters: {'rf_n_estimators': 136, 'rf_max_depth': 8, 'nn_units1': 129, 'nn_units2': 57, 'nn_alpha': 3.8234752246751835e-05}. Best is trial 3 with value: 0.8815891880052097.\n",
      "[I 2025-06-09 15:04:45,386] Trial 4 finished with value: 0.8199391614996826 and parameters: {'rf_n_estimators': 222, 'rf_max_depth': 6, 'nn_units1': 94, 'nn_units2': 52, 'nn_alpha': 8.168455894760161e-05}. Best is trial 3 with value: 0.8815891880052097.\n",
      "[I 2025-06-09 15:05:00,755] Trial 5 finished with value: 0.8917248262585115 and parameters: {'rf_n_estimators': 257, 'rf_max_depth': 7, 'nn_units1': 127, 'nn_units2': 70, 'nn_alpha': 1.2385137298860926e-05}. Best is trial 5 with value: 0.8917248262585115.\n",
      "[I 2025-06-09 15:05:10,131] Trial 6 finished with value: 0.8645987986991053 and parameters: {'rf_n_estimators': 222, 'rf_max_depth': 6, 'nn_units1': 59, 'nn_units2': 97, 'nn_alpha': 0.0008536189862866829}. Best is trial 5 with value: 0.8917248262585115.\n",
      "[I 2025-06-09 15:05:19,750] Trial 7 finished with value: 0.8655607670181469 and parameters: {'rf_n_estimators': 262, 'rf_max_depth': 8, 'nn_units1': 64, 'nn_units2': 77, 'nn_alpha': 7.591104805282687e-05}. Best is trial 5 with value: 0.8917248262585115.\n",
      "[I 2025-06-09 15:05:26,675] Trial 8 finished with value: 0.8327590848312244 and parameters: {'rf_n_estimators': 124, 'rf_max_depth': 10, 'nn_units1': 55, 'nn_units2': 94, 'nn_alpha': 3.292759134423613e-05}. Best is trial 5 with value: 0.8917248262585115.\n",
      "[I 2025-06-09 15:05:35,425] Trial 9 finished with value: 0.8615511861674163 and parameters: {'rf_n_estimators': 233, 'rf_max_depth': 8, 'nn_units1': 128, 'nn_units2': 66, 'nn_alpha': 2.3426581058204037e-05}. Best is trial 5 with value: 0.8917248262585115.\n",
      "[I 2025-06-09 15:05:44,151] Trial 10 finished with value: 0.9031375481288276 and parameters: {'rf_n_estimators': 295, 'rf_max_depth': 12, 'nn_units1': 98, 'nn_units2': 26, 'nn_alpha': 1.0691211811484811e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:05:55,357] Trial 11 finished with value: 0.8856364634052252 and parameters: {'rf_n_estimators': 287, 'rf_max_depth': 12, 'nn_units1': 99, 'nn_units2': 31, 'nn_alpha': 1.0173098453440401e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:06:04,405] Trial 12 finished with value: 0.883874558680824 and parameters: {'rf_n_estimators': 300, 'rf_max_depth': 12, 'nn_units1': 98, 'nn_units2': 28, 'nn_alpha': 1.0814159550424566e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:06:16,353] Trial 13 finished with value: 0.8768628200311619 and parameters: {'rf_n_estimators': 267, 'rf_max_depth': 12, 'nn_units1': 148, 'nn_units2': 84, 'nn_alpha': 0.00019575500799074534}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:06:24,844] Trial 14 finished with value: 0.8647545398164794 and parameters: {'rf_n_estimators': 259, 'rf_max_depth': 10, 'nn_units1': 112, 'nn_units2': 47, 'nn_alpha': 1.0715330101892688e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:06:34,316] Trial 15 finished with value: 0.8609915598487992 and parameters: {'rf_n_estimators': 184, 'rf_max_depth': 13, 'nn_units1': 200, 'nn_units2': 39, 'nn_alpha': 4.303296098673269e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:06:46,830] Trial 16 finished with value: 0.8776196056613895 and parameters: {'rf_n_estimators': 279, 'rf_max_depth': 9, 'nn_units1': 79, 'nn_units2': 81, 'nn_alpha': 1.609990408498778e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:06:57,880] Trial 17 finished with value: 0.8518338440502374 and parameters: {'rf_n_estimators': 242, 'rf_max_depth': 13, 'nn_units1': 138, 'nn_units2': 59, 'nn_alpha': 0.00022579491669713815}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:07:09,273] Trial 18 finished with value: 0.868880467041098 and parameters: {'rf_n_estimators': 300, 'rf_max_depth': 7, 'nn_units1': 112, 'nn_units2': 37, 'nn_alpha': 4.9672624554072564e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:07:16,296] Trial 19 finished with value: 0.8451470187676315 and parameters: {'rf_n_estimators': 195, 'rf_max_depth': 11, 'nn_units1': 78, 'nn_units2': 25, 'nn_alpha': 0.00013941323718227167}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:07:31,895] Trial 20 finished with value: 0.878758024704258 and parameters: {'rf_n_estimators': 246, 'rf_max_depth': 14, 'nn_units1': 149, 'nn_units2': 89, 'nn_alpha': 0.0005231779961784009}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:07:44,546] Trial 21 finished with value: 0.863270749587753 and parameters: {'rf_n_estimators': 284, 'rf_max_depth': 11, 'nn_units1': 109, 'nn_units2': 32, 'nn_alpha': 1.4011261252470006e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:07:59,997] Trial 22 finished with value: 0.8783601696822583 and parameters: {'rf_n_estimators': 284, 'rf_max_depth': 12, 'nn_units1': 87, 'nn_units2': 47, 'nn_alpha': 1.0097954310561069e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:08:08,521] Trial 23 finished with value: 0.8417045103679419 and parameters: {'rf_n_estimators': 277, 'rf_max_depth': 11, 'nn_units1': 104, 'nn_units2': 32, 'nn_alpha': 1.6851893077073653e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:08:19,741] Trial 24 finished with value: 0.8800759767345041 and parameters: {'rf_n_estimators': 300, 'rf_max_depth': 13, 'nn_units1': 73, 'nn_units2': 75, 'nn_alpha': 2.742288310354306e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:08:31,019] Trial 25 finished with value: 0.8617679792491028 and parameters: {'rf_n_estimators': 255, 'rf_max_depth': 9, 'nn_units1': 120, 'nn_units2': 46, 'nn_alpha': 1.4566270530498352e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:08:39,967] Trial 26 finished with value: 0.8639981566667431 and parameters: {'rf_n_estimators': 215, 'rf_max_depth': 10, 'nn_units1': 119, 'nn_units2': 33, 'nn_alpha': 5.986368841592828e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:08:49,468] Trial 27 finished with value: 0.8431220567170842 and parameters: {'rf_n_estimators': 275, 'rf_max_depth': 14, 'nn_units1': 90, 'nn_units2': 64, 'nn_alpha': 1.4821008521655924e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:08:58,638] Trial 28 finished with value: 0.8676064196527761 and parameters: {'rf_n_estimators': 288, 'rf_max_depth': 5, 'nn_units1': 134, 'nn_units2': 25, 'nn_alpha': 3.333913743218505e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:09:06,971] Trial 29 finished with value: 0.8282191293671278 and parameters: {'rf_n_estimators': 164, 'rf_max_depth': 14, 'nn_units1': 159, 'nn_units2': 56, 'nn_alpha': 2.0792802311763545e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:09:17,744] Trial 30 finished with value: 0.840405646972967 and parameters: {'rf_n_estimators': 246, 'rf_max_depth': 9, 'nn_units1': 140, 'nn_units2': 70, 'nn_alpha': 1.9906076702405317e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:09:30,186] Trial 31 finished with value: 0.8962391292960964 and parameters: {'rf_n_estimators': 297, 'rf_max_depth': 12, 'nn_units1': 101, 'nn_units2': 29, 'nn_alpha': 1.0578748411446197e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:09:37,472] Trial 32 finished with value: 0.8789361627849315 and parameters: {'rf_n_estimators': 290, 'rf_max_depth': 12, 'nn_units1': 101, 'nn_units2': 30, 'nn_alpha': 1.2063047582892954e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:09:47,304] Trial 33 finished with value: 0.8349609849213764 and parameters: {'rf_n_estimators': 265, 'rf_max_depth': 11, 'nn_units1': 89, 'nn_units2': 36, 'nn_alpha': 1.884094197268003e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:09:57,954] Trial 34 finished with value: 0.8428832411803527 and parameters: {'rf_n_estimators': 269, 'rf_max_depth': 13, 'nn_units1': 118, 'nn_units2': 42, 'nn_alpha': 1.0176608322623119e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:10:07,836] Trial 35 finished with value: 0.8630422505870037 and parameters: {'rf_n_estimators': 291, 'rf_max_depth': 15, 'nn_units1': 69, 'nn_units2': 42, 'nn_alpha': 2.7660421729214138e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:10:16,427] Trial 36 finished with value: 0.8667216340655832 and parameters: {'rf_n_estimators': 251, 'rf_max_depth': 12, 'nn_units1': 83, 'nn_units2': 51, 'nn_alpha': 1.305755529247273e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:10:23,578] Trial 37 finished with value: 0.8682215807424829 and parameters: {'rf_n_estimators': 234, 'rf_max_depth': 7, 'nn_units1': 97, 'nn_units2': 28, 'nn_alpha': 2.483002048693721e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:10:29,511] Trial 38 finished with value: 0.8823718788393002 and parameters: {'rf_n_estimators': 158, 'rf_max_depth': 10, 'nn_units1': 105, 'nn_units2': 34, 'nn_alpha': 0.00011655108689146477}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:10:38,033] Trial 39 finished with value: 0.8541687709518432 and parameters: {'rf_n_estimators': 100, 'rf_max_depth': 11, 'nn_units1': 126, 'nn_units2': 73, 'nn_alpha': 0.0003617392956285575}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:10:48,598] Trial 40 finished with value: 0.8744081229962182 and parameters: {'rf_n_estimators': 209, 'rf_max_depth': 5, 'nn_units1': 167, 'nn_units2': 67, 'nn_alpha': 1.7143521398011583e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:10:57,610] Trial 41 finished with value: 0.8862450610496101 and parameters: {'rf_n_estimators': 298, 'rf_max_depth': 12, 'nn_units1': 98, 'nn_units2': 28, 'nn_alpha': 1.2836405449342938e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:11:11,040] Trial 42 finished with value: 0.884846908399116 and parameters: {'rf_n_estimators': 291, 'rf_max_depth': 12, 'nn_units1': 94, 'nn_units2': 25, 'nn_alpha': 1.270522612947946e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:11:20,284] Trial 43 finished with value: 0.8655059039205835 and parameters: {'rf_n_estimators': 273, 'rf_max_depth': 13, 'nn_units1': 111, 'nn_units2': 29, 'nn_alpha': 1.2961566065254952e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:11:35,409] Trial 44 finished with value: 0.8523807482737029 and parameters: {'rf_n_estimators': 297, 'rf_max_depth': 11, 'nn_units1': 120, 'nn_units2': 38, 'nn_alpha': 2.098011338703736e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:11:46,577] Trial 45 finished with value: 0.8411355351516392 and parameters: {'rf_n_estimators': 282, 'rf_max_depth': 14, 'nn_units1': 101, 'nn_units2': 60, 'nn_alpha': 1.0173221349132161e-05}. Best is trial 10 with value: 0.9031375481288276.\n",
      "[I 2025-06-09 15:11:54,867] Trial 46 finished with value: 0.9076459770812584 and parameters: {'rf_n_estimators': 262, 'rf_max_depth': 12, 'nn_units1': 59, 'nn_units2': 29, 'nn_alpha': 1.6023703509843143e-05}. Best is trial 46 with value: 0.9076459770812584.\n",
      "[I 2025-06-09 15:12:01,478] Trial 47 finished with value: 0.8733704464501043 and parameters: {'rf_n_estimators': 235, 'rf_max_depth': 6, 'nn_units1': 54, 'nn_units2': 35, 'nn_alpha': 3.518232139693851e-05}. Best is trial 46 with value: 0.9076459770812584.\n",
      "[I 2025-06-09 15:12:07,839] Trial 48 finished with value: 0.8787178579414199 and parameters: {'rf_n_estimators': 260, 'rf_max_depth': 7, 'nn_units1': 63, 'nn_units2': 81, 'nn_alpha': 0.0009921267796317273}. Best is trial 46 with value: 0.9076459770812584.\n",
      "[I 2025-06-09 15:12:17,056] Trial 49 finished with value: 0.8698994421432795 and parameters: {'rf_n_estimators': 269, 'rf_max_depth': 10, 'nn_units1': 50, 'nn_units2': 40, 'nn_alpha': 1.699900096532071e-05}. Best is trial 46 with value: 0.9076459770812584.\n"
     ]
    }
   ],
   "source": [
    "# Create Optuna study and optimize\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e47dc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  R2 Score: 0.9076\n",
      "  Params:\n",
      "    rf_n_estimators: 262\n",
      "    rf_max_depth: 12\n",
      "    nn_units1: 59\n",
      "    nn_units2: 29\n",
      "    nn_alpha: 1.6023703509843143e-05\n"
     ]
    }
   ],
   "source": [
    "# Output best trial results\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  R2 Score: {trial.value:.4f}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d51b4c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best hyperparameters\n",
    "best_rf_n_estimators = trial.params['rf_n_estimators']\n",
    "best_rf_max_depth = trial.params['rf_max_depth']\n",
    "best_nn_units1 = trial.params['nn_units1']\n",
    "best_nn_units2 = trial.params['nn_units2']\n",
    "best_nn_alpha = trial.params['nn_alpha']\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=best_rf_n_estimators,\n",
    "    max_depth=best_rf_max_depth,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "nn_model = MLPRegressor(\n",
    "    hidden_layer_sizes=(best_nn_units1, best_nn_units2),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    random_state=42,\n",
    "    max_iter=500,\n",
    "    alpha=best_nn_alpha,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "meta_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "stacking_regressor = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('nn', nn_model),\n",
    "    ],\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    passthrough=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81e848ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final R2 Score: 0.9076\n",
      "Final MSE: 0.3784\n"
     ]
    }
   ],
   "source": [
    "# Fit final model\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Final evaluation on test set\n",
    "y_pred = stacking_regressor.predict(X_test)\n",
    "print(f\"Final R2 Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Final MSE: {mean_squared_error(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce65c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature keys (column names):\n",
      "['Gender', 'Age', 'Occupation', 'Sleep Duration', 'Physical Activity Level', 'Stress Level', 'BMI Category', 'Blood Pressure', 'Heart Rate', 'Daily Steps']\n"
     ]
    }
   ],
   "source": [
    "# Get the feature names (keys)\n",
    "feature_keys = X.columns.tolist()\n",
    "print(\"Feature keys (column names):\")\n",
    "print(feature_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb28a5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'Gender' unique values (2): ['Male' 'Female']\n",
      "\n",
      "Feature 'Age' unique values (44): [27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 48 49 50 51 52\n",
      " 53 54 55 56 57 58 59 46 62 20 47 26 63 23 24 22 64 18 19 25]\n",
      "\n",
      "Feature 'Occupation' unique values (14): ['Software Engineer' 'Doctor' 'Sales Representative' 'Teacher' 'Nurse'\n",
      " 'Engineer' 'Accountant' 'Scientist' 'Lawyer' 'Salesperson' 'Manager'\n",
      " 'Unemployed' 'Student' 'Self-employed']\n",
      "\n",
      "Feature 'Sleep Duration' unique values (463): [ 6.1         6.2         5.9         6.3         7.8         6.\n",
      "  6.5         7.6         7.7         7.9         6.4         7.5\n",
      "  7.2         5.8         6.7         7.3         7.1         6.6\n",
      "  7.4         6.9         8.          6.8         8.1         8.3\n",
      "  8.5         8.4         8.2         5.5         8.8         5.4\n",
      " 10.2         9.2         5.3        11.8         9.4         4.2\n",
      " 10.3         5.          4.4         1.8         9.1         9.7\n",
      "  8.9         5.2         4.3         4.9         4.5         8.7\n",
      "  9.6         5.6        10.20408657 10.20141971 10.19619976 10.19788117\n",
      " 10.24760075 10.16580347 10.16097069 10.19013239 10.23687407 10.24640204\n",
      " 10.20128523 10.21407269 10.20234214 10.19775008 10.22796568 10.22918108\n",
      "  7.52575757  7.51768516  7.46771778  7.45202386  7.50864199  7.48262432\n",
      "  7.51295279  7.48862838  7.48334257  7.52312637  7.55234667  7.4830499\n",
      "  7.53317658  7.49324611  7.53159747  7.48279942  5.50624944  5.53297068\n",
      "  5.52133222  5.52218138  5.51241249  5.43962403  5.46197968  5.50961666\n",
      "  5.51190329  5.52416538  5.48375344  5.49479078  5.45334617  5.45218113\n",
      "  5.44119837  5.4845095   5.20502364  5.20982409  5.17465734  5.16900426\n",
      "  5.16813724  5.22255785  5.23993748  5.1654943   5.1712708   5.22670294\n",
      "  5.20219052  5.23121225  5.23009333  5.22091696  5.27853924  5.20403122\n",
      "  8.27713057  8.31422505  8.29297371  8.29405569  8.3101985   8.23482204\n",
      "  8.27561023  8.30891978  8.28427847  8.32056821  8.25495604  8.30670176\n",
      "  8.29571028  8.28871342  8.26368954  8.29967479  8.77916222  8.80716899\n",
      "  8.83916706  8.83052673  8.78549861  8.8120757   8.84349204  8.816213\n",
      "  8.77677291  8.77914112  8.85176075  8.77553033  8.80596443  8.80144004\n",
      "  8.82050887  8.7919539   8.28906397  8.17165018  8.14988283  8.24462883\n",
      "  8.22070789  8.18783719  8.17133158  8.17282566  8.21292962  8.17128267\n",
      "  8.1921512   8.22902936  8.22904903  8.21426294  8.1806766   8.19807152\n",
      "  8.09650418  8.14490745  8.13251433  8.12427701  8.14501092  8.09020161\n",
      "  8.07594453  8.11520301  8.05902741  8.1199485   8.02289048  8.05406027\n",
      "  8.15853515  8.08176816  8.11852768  8.07912904  6.26032106  6.25255964\n",
      "  6.29252774  6.33856864  6.32929521  6.31406001  6.37213378  6.30725032\n",
      "  6.33020079  6.24966603  6.27417839  6.2708347   6.29854562  6.33211896\n",
      "  6.27606567  6.29134673  8.4064342   8.38484959  8.38020533  8.37769934\n",
      "  8.39357546  8.3819793   8.45802375  8.40341908  8.40913343  8.4036896\n",
      "  8.38857519  8.44633909  8.38950569  8.3989177   8.42178545  8.39590523\n",
      "  5.89299362  5.92177691  5.93230702  5.91777037  5.91735398  5.87511078\n",
      "  5.92716867  5.87854619  5.93779704  5.93875324  5.96039191  5.87026422\n",
      "  5.90262129  5.83951149  5.89416389  5.85632462  5.76797738  5.84304997\n",
      "  5.80412239  5.81498578  5.81074372  5.7569042   5.81332322  5.80530198\n",
      "  5.79249688  5.75986688  5.7899463   5.78361931  5.80290317  5.81045649\n",
      "  5.74790933  5.85058415  5.83344056  5.84415851  5.76437139  5.79411569\n",
      "  5.81969379  5.72725371  5.80656163  5.77147414  5.78167575  5.83817214\n",
      "  5.73743754  5.80638129  5.82839944  5.88825151  5.88798535  5.82855352\n",
      "  5.92747763  5.84623492  5.92113073  5.88096309  5.8681367   5.90395607\n",
      "  5.88708365  5.88835726  5.86554201  5.90911572  5.91804584  5.39479507\n",
      "  5.37629463  5.39412297  5.395438    5.37162196  5.46502415  5.38437036\n",
      "  5.42667708  5.40794428  5.43035239  5.34756452  5.37039275  5.36558551\n",
      "  5.3880991   5.37911919  5.40099109  5.93317009  5.91581675  5.91136823\n",
      "  5.94290444  5.9279983   5.9042146   5.8854236   5.92711571  5.86818912\n",
      "  5.86542499  5.88618062  5.92223031  7.48219535  7.48384861  7.48476827\n",
      "  7.46523822  7.48075013  7.48574014  7.49893333  7.51952139  7.48108602\n",
      "  7.48131926  7.48708606  7.4874192   7.51521705  7.4821942   7.53101033\n",
      "  7.48920355  5.87293768  5.92236612  5.88963066  5.9024229   5.86531204\n",
      "  5.88394317  5.89345277  5.9028942   5.85349814  5.90519389  5.87892897\n",
      "  5.90281429  5.89349776  5.84910253  5.94833301  5.93592774  6.91654778\n",
      "  6.90466782  6.90536537  6.93864731  6.90949166  6.884358    6.8953999\n",
      "  6.9366473   6.87443474  6.88592902  6.93696996  6.89391623  6.92058733\n",
      "  6.93684483  6.89671852  6.88163849  7.36365455  7.43203364  7.37088146\n",
      "  7.42404016  7.46345967  7.39679061  7.40865897  7.43014279  7.43944595\n",
      "  7.41108132  7.38837115  7.38523014  7.37115229  7.44499813  7.40303792\n",
      "  7.44726902  5.77660814  5.80453255  5.82343957  5.85280608  5.78800327\n",
      "  5.76060021  5.77644801  5.74645738  5.77217733  5.82170542  5.84292471\n",
      "  5.8086081   5.77551381  5.80162235  5.76212642  5.76132798  7.10869013\n",
      "  7.10539878  7.06211703  7.11420824  7.10414737  7.08359065  7.14190764\n",
      "  7.08913774  7.09366684  7.11789081  7.06982896  7.07596914  7.03048491\n",
      "  7.06492186  7.13751353  7.13467899  4.89531894  4.90933508  4.92683728\n",
      "  4.96222098  4.9209544   4.91602961  4.8813399   4.85041409  4.92385151\n",
      "  4.89061881  4.86142681  4.89918484  4.90613563  4.90644279  4.90199607\n",
      "  4.90866048  5.9850701   6.01046089  6.05380906  6.01412256  5.94356792\n",
      "  5.99710813  6.02092945  5.97514303  6.02761932  6.00634102  5.99899735\n",
      "  5.95403254  6.03751512  5.97544834  6.03615754  5.96477263 10.27189611\n",
      " 10.31743336 10.29100654 10.2910996  10.31843086 10.29575419 10.30026186\n",
      " 10.32432306 10.37510248 10.26397937 10.31942108 10.2660307  10.30800454\n",
      " 10.33343494 10.28283649 10.28270758  5.173196    8.33459187  5.93911776\n",
      "  5.36829515  6.29577823  5.55596753  5.96279601  7.52369605  5.93817259\n",
      "  6.88464728  7.46193797  5.91890485  5.92842273  5.78029542  8.17275621\n",
      " 10.28261526  8.10040993  5.79098873 10.20174883  8.79926249  5.84505284\n",
      "  4.87695738]\n",
      "\n",
      "Feature 'Physical Activity Level' unique values (60): [42 60 30 40 75 35 45 50 32 70 80 55 90 47 65 85 20 29 27 52  1  7 44 58\n",
      " 43 26 38 56 53 16 54  5 15 24 12 22 36 51  4 49  0 21  2 13 39 41 25 37\n",
      " 28  9 46 18  8 11 48 34 23  6 14 31]\n",
      "\n",
      "Feature 'Stress Level' unique values (509): [ 6.          8.          7.          4.          3.          5.\n",
      "  4.53169325  3.83824373  5.4441578   3.50184695  2.24412139  6.57106425\n",
      "  5.64816794  4.58566822  6.66959084  1.          7.95578809  3.94047959\n",
      "  5.59224055  5.6026456   4.11646795  3.44932779  6.57934561  5.85602568\n",
      "  5.45491987  6.23528169  8.73154902  5.84897249  4.71820289  4.97683336\n",
      "  3.78125325  2.94900026  2.63346876  2.59973652  8.12076028  2.3841714\n",
      "  2.34633647  4.4948637   4.59508495  7.27403484  8.10984535  6.10347402\n",
      "  6.52895647  5.78408378  8.62733315  1.83669215  5.64543712  5.44818496\n",
      "  7.4008231   5.92544863  8.45549525  5.28410018  5.51733382  5.0104874\n",
      "  2.26281977  7.35859437  3.07015308  8.0047141   3.4951066   4.78593928\n",
      "  6.70270853  6.15311393  3.70685423  9.74865881  2.20286485  5.34793266\n",
      "  2.72171654  5.33945857  6.03224946  8.54475597  6.78482164  8.41164972\n",
      "  8.28419234  6.62737715 10.          1.88850005  4.46222262  4.10394572\n",
      "  1.93064304  7.82992738  5.19749156  4.44838087  5.45452282  1.49306117\n",
      "  9.31047908  1.74081403  4.80227425  4.54998819  6.53596654  2.36130422\n",
      "  4.85966858  5.71505249  2.18968016  4.95144544  4.39927902  4.66855389\n",
      "  7.22110874  7.28571886  7.2375223   7.20298252  7.30455057  7.25881465\n",
      "  7.30177761  7.21314711  7.37683075  7.20058233  7.27441903  7.19532217\n",
      "  7.23034324  7.30858689  7.33529268  7.35110475  8.08172291  8.12793762\n",
      "  8.13386173  8.18047957  8.0861698   8.10835597  8.00400094  8.08627023\n",
      "  8.0586504   8.05203722  8.13712785  8.09585753  8.11497812  8.11105622\n",
      "  8.11325116  8.04492511  1.94145399  1.91856921  1.9407323   1.8974928\n",
      "  1.89356881  1.94366808  1.76758052  1.86977448  1.92862124  1.92085241\n",
      "  1.94525386  1.90713237  1.83303123  1.95191209  1.88484494  1.89052068\n",
      "  6.75232718  6.7860052   6.83727185  6.75396928  6.70620622  6.80293649\n",
      "  6.77047427  6.78503347  6.79706763  6.8651889   6.8312017   6.80516917\n",
      "  6.76955338  6.82208214  6.75489399  6.6895255   5.66001766  5.69355048\n",
      "  5.63751299  5.54873273  5.59135282  5.59022838  5.6060616   5.56651612\n",
      "  5.56972362  5.60414966  5.64008134  5.57537571  5.52164445  5.70762115\n",
      "  5.60395702  5.59633607  8.65929551  8.62181207  8.66692811  8.60742712\n",
      "  8.59117917  8.70791258  8.56379043  8.60490833  8.56236078  8.58247768\n",
      "  8.64584051  8.71498695  8.5648181   8.61721871  8.61611929  8.67787379\n",
      "  2.16130898  2.30736361  2.23827015  2.27361237  2.30244975  2.25585803\n",
      "  2.23717361  2.24248378  2.21592267  2.23546802  2.25089185  2.26024958\n",
      "  2.2393224   2.19098352  2.28002531  2.17559987  5.16358399  5.26869881\n",
      "  5.17088793  5.18697303  5.22745931  5.1822454   5.1631945   5.20198826\n",
      "  5.26247862  5.14345136  5.24785764  5.19231979  5.13697212  5.16610486\n",
      "  5.18594129  5.18492893  5.90205576  5.88009551  5.84471132  5.82134217\n",
      "  5.80686243  5.83098253  5.82813954  5.97478693  5.86524635  5.87386319\n",
      "  5.84096874  5.87916814  5.86335001  5.80607919  5.88235508  5.84182319\n",
      "  6.24426759  6.19040216  6.31679049  6.14729614  6.26564675  6.22378084\n",
      "  6.20943147  6.20724353  6.18680712  6.23703029  6.32196263  6.18175141\n",
      "  6.22737311  6.20053812  6.2940741   6.21002333  8.03031313  8.01422184\n",
      "  7.97362522  7.98273559  8.035183    7.92701506  8.05518826  7.98468979\n",
      "  8.02657367  8.03142341  8.01980814  7.94468092  8.05001808  7.98766822\n",
      "  7.92623037  8.01366538  8.03418974  8.04198413  7.94109673  7.98482259\n",
      "  7.93440724  7.95779813  8.07079632  7.9753354   7.93169106  8.00349014\n",
      "  8.01088656  7.99223498  8.02828167  8.08006725  7.97272035  7.9510401\n",
      "  7.94498473  7.95624395  7.98021078  7.99638218  8.0548575   8.09251195\n",
      "  8.02281234  7.91912244  7.97105397  7.98781379  8.01450842  7.96017403\n",
      "  8.00885006  7.92903704  8.00087858  8.00388682  8.03740601  7.95972731\n",
      "  8.0538605   7.92564833  8.04068885  8.01632746  7.92138066  7.97877892\n",
      "  7.99796795  7.98828935  7.96293143  4.06280978  4.11898377  4.14933105\n",
      "  4.13870532  4.13359948  4.09811131  4.07778014  4.06077454  4.07975296\n",
      "  4.16250687  4.06909666  4.06895058  4.23862873  4.12601664  4.13536573\n",
      "  4.06842613  7.92198577  7.9750384   8.00619414  8.05521339  8.04571774\n",
      "  7.95222502  8.09814685  8.05991484  7.98520686  7.97373119  8.01077648\n",
      "  8.02400488  3.49474976  3.48596022  3.57251716  3.46027832  3.51924155\n",
      "  3.42319496  3.48347723  3.52446832  3.48617313  3.47809614  3.5191107\n",
      "  3.36999749  3.45598511  3.51296267  3.54050175  3.53952229  7.38621378\n",
      "  7.37025167  7.36971978  7.44717704  7.39978389  7.38155658  7.39667761\n",
      "  7.39493132  7.44085671  7.3875107   7.37835484  7.44885738  7.34956305\n",
      "  7.35334271  7.4207746   7.38488229  6.76541575  6.74754701  6.63556047\n",
      "  6.71633989  6.6860101   6.64239894  6.62427871  6.77969601  6.67480106\n",
      "  6.77371525  6.72878454  6.77161087  6.60981531  6.73967018  6.6460966\n",
      "  6.81480831  2.68994565  2.70570302  2.69084484  2.71846611  2.72614898\n",
      "  2.77811923  2.65251942  2.7712321   2.733874    2.70247287  2.74610497\n",
      "  2.74659796  2.68908068  2.6971477   2.72266115  2.7431683   0.96122473\n",
      "  1.01945393  1.01108395  0.96385526  0.95521634  0.92758727  0.99968035\n",
      "  0.9968117   0.99719025  0.94075442  1.0190263   1.10137223  1.13520961\n",
      "  0.96928992  1.00505156  0.97047365  5.34499705  5.25243643  5.31825568\n",
      "  5.41402333  5.3970175   5.36501776  5.41286116  5.29629244  5.37244834\n",
      "  5.4170304   5.38229277  5.41776108  5.35391509  5.31060436  5.41589179\n",
      "  5.30690113  7.85147892  7.8361451   7.78607921  7.81794243  7.83843997\n",
      "  7.81563449  7.83732202  7.86069785  7.89424917  7.80165521  7.82122031\n",
      "  7.86481534  7.8058688   7.81532066  7.78952863  7.88170411  2.30481808\n",
      "  2.23596623  2.32494313  2.25686165  2.20666434  2.30233355  2.24841349\n",
      "  2.2105969   2.30295011  2.16852951  2.24712203  2.24198653  2.22791955\n",
      "  2.20315318  2.28674906  2.29515586  5.93613373  5.95433082  5.885088\n",
      "  5.90535301  5.9610157   5.98070006  5.86437192  6.00146037  5.88047113\n",
      "  5.90375469  5.94319136  5.97247562  5.86442173  5.82868853  5.90520475\n",
      "  5.85494618  6.86681852  5.59448445  2.28940712  4.08858684  5.7910335\n",
      "  1.88360367  8.08868882  3.46162047  7.35553334  6.73047112  8.08379379\n",
      "  7.99254404  8.06787716  1.01493901  2.32272362  5.88421988  5.13619149\n",
      "  8.02005397  7.14125346  8.66529488  7.99165407  7.76820709]\n",
      "\n",
      "Feature 'BMI Category' unique values (5): ['Overweight' 'Normal' 'Obese' 'Normal Weight' 'Underweight']\n",
      "\n",
      "Feature 'Blood Pressure' unique values (113): ['126/83' '125/80' '140/90' '120/80' '132/87' '130/86' '117/76' '118/76'\n",
      " '128/85' '131/86' '128/84' '115/75' '129/84' '130/85' '135/88' '115/78'\n",
      " '119/77' '121/79' '125/82' '135/90' '122/80' '142/92' '140/95' '139/91'\n",
      " '118/75' '113/80' '101/85' '92/64' '133/88' '118/77' '110/75' '96/68'\n",
      " '126/74' '102/78' '121/66' '100/85' '97/86' '138/85' '90/78' '113/64'\n",
      " '125/78' '100/87' '91/60' '97/63' '130/63' '101/86' '122/87' '95/62'\n",
      " '107/84' '98/70' '135/75' '111/85' '94/66' '115/64' '105/78' '99/81'\n",
      " '116/79' '132/71' '130/66' '138/62' '124/68' '108/85' '98/69' '134/60'\n",
      " '128/89' '102/87' '124/78' '100/71' '139/87' '102/73' '122/81' '130/62'\n",
      " '126/69' '121/61' '94/89' '123/65' '131/78' '116/88' '123/76' '104/74'\n",
      " '136/87' '106/72' '138/71' '95/65' '104/65' '132/62' '124/60' '108/86'\n",
      " '127/60' '118/65' '102/74' '129/89' '98/80' '132/86' '129/76' '118/89'\n",
      " '93/60' '121/77' '107/66' '91/62' '111/71' '111/70' '114/65' '106/85'\n",
      " '128/67' '124/62' '113/78' '115/68' '97/77' '123/62' '133/74' '93/77'\n",
      " '135/83']\n",
      "\n",
      "Feature 'Heart Rate' unique values (40): [77 75 85 82 70 80 78 69 72 68 76 81 65 74 84 67 73 83 86 95 66 91 87 71\n",
      " 61 93 97 92 96 90 98 63 64 88 89 62 79 94 60 99]\n",
      "\n",
      "Feature 'Daily Steps' unique values (452): [ 4200 10000  3000  3500  8000  4000  4100  6800  5000  7000  5500  5200\n",
      "  5600  4800  3300  7500  7300  6200  6000  3700  4531  3949  3464  3443\n",
      "  4293 10312  4229  3753  5593  6643  3963  6026  5522  2082  4831  6546\n",
      "  5862    60  7614  7434  5947  6881  6744  5381  3372  2633  5989  7402\n",
      "  5257  1018  8687  2504  5121  5893  3037  3579  2777  4750  5809  5158\n",
      "  8140  3345  5025  8632  2918  2014  7074  7465  5093  6070  5135  6372\n",
      "  5148  8347  2929  3759  5622  2836  7029  6125  6815  5535  5178  5950\n",
      "  4203  5191  4935  4922  1997  6047  -569  2786   751 10592  5250  4739\n",
      "  2884  6495  3910  6344  6103  9595  7415  8202  4547  1678  3825  6002\n",
      "  3889  3390  3348  5904  5907  5928  5980  5865  5901  5892  5929  5924\n",
      "  5859  5878  5832  5798  5917  5920  5321  5316  5268  5226  5227  5208\n",
      "  5304  5295  5267  5218  5219  5271  5292  5301  5231     0  5196  5205\n",
      "  5155  5234  5190  5129  5211  5173  5183  5199  5221  5259  5319  5512\n",
      "  5525  5486  5513  5634  5550  5489  5541  5547  5491  5506  5449  5545\n",
      "  5475  5811  5877  5803  5812  5863  5817  5849  5777  5728  5861  5756\n",
      "  5814  5840  5738  4298  4347  4284  4297  4247  4274  4374  4323  4283\n",
      "  4241  4296  4267  4290  4250  4312  4329  4787  4791  4762  4708  4716\n",
      "  4749  4693  4694  4746  4733  4713  4667  4724  4848  6904  6902  6866\n",
      "  6940  6914  6955  6819  6934  6863  6890  6917  6855  6833  6893  6844\n",
      "  7460  7412  7482  7452  7462  7416  7419  7411  7477  7479  7447  7437\n",
      "  7515  7385  2945  2997  2979  2996  3056  2982  2953  2977  3031  3040\n",
      "  3015  2970  2995  3004  2994  3069  5242  5132  5325  5117  5256  5193\n",
      "  5164  5157  5254  5230  5174  5166  5248  5207  5229  5176  5201  5198\n",
      "  5260  3010  2981  3032  3009  3027  3025  2971  3045  2980  3006  3016\n",
      "  4864  4877  4815  4741  4881  4856  4760  4782  4799  4852  4822  4894\n",
      "  4845  4834  4794  2999  3096  3019  2960  2987  3088  2975  2992  2934\n",
      "  8358  8309  8383  8326  8324  8327  8382  8323  8254  8360  8321  8398\n",
      "  8349  8284  8610  8569  8549  8613  8660  8592  8629  8653  8658  8623\n",
      "  8625  8627  8586  8655  8652  3760  3734  3800  3763  3739  3771  3785\n",
      "  3773  3709  3718  3790  3742  5591  5608  5510  5501  5559  5497  5530\n",
      "  5556  5565  5564  5617  5474  5503  5563  6590  6632  6605  6603  6627\n",
      "  6642  6602  6569  6614  6617  6710  6654  6625  6661  6624  6656  6768\n",
      "  6786  6830  6775  6795  6832  6821  6817  6766  6774  6809  6784  5232\n",
      "  5276  5269  5265  5277  5287  5253  5330  5237  5240  5280  6119  6175\n",
      "  6040  6093  6074  6051  6007  6057  6073  6113  6104  6131  6133  6020\n",
      "  6060  2910  2826  2896  2908  2913  2965  2943  2930  2893  2942  2915\n",
      "  2887  2877  2888  3001  2901  5505  6014  4898  6870  8356  8680  3740\n",
      "  5306  3008  6684  2911  4701  5217  5912  5273]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    unique_vals = X[col].unique()\n",
    "    print(f\"Feature '{col}' unique values ({len(unique_vals)}): {unique_vals}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9429fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
